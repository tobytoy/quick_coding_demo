import streamlit as st
import os
import ffmpeg
import whisper
import cv2
import google.generativeai as genai
from skimage.metrics import structural_similarity as ssim
import numpy as np
import soundfile as sf
import noisereduce as nr
import tempfile
import time

# --- UI è¨­å®š ---
st.set_page_config(page_title="å½±ç‰‡ Hashtag è‡ªå‹•ç”Ÿæˆå™¨", layout="wide")
st.title("å½±ç‰‡ Hashtag è‡ªå‹•ç”Ÿæˆç³»çµ± (Gemini POC)")
st.markdown("ä¸€å€‹åŸºæ–¼å¤šæ¨¡æ…‹ AI çš„æ¦‚å¿µé©—è­‰ï¼Œå¾å½±ç‰‡çš„è²éŸ³å’Œç•«é¢ä¸­è‡ªå‹•æå–ä¸¦ç”Ÿæˆç›¸é—œçš„ Hashtagã€‚")

# åœ¨å´é‚Šæ¬„ç²å– API Key
st.sidebar.header("è¨­å®š")
api_key = st.sidebar.text_input("è«‹è¼¸å…¥æ‚¨çš„ Google Gemini API Key", type="password")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³æ‚¨çš„å½±ç‰‡æª”æ¡ˆ (mp4, mov, avi)", type=["mp4", "mov", "avi"])

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

# 1. éŸ³è¨Šè™•ç†
def process_audio(video_path, temp_dir):
    """æå–ã€é™å™ªä¸¦è¾¨è­˜éŸ³è¨Š"""
    st.info("ğŸ”Š éŸ³è¨Šæµç¨‹é–‹å§‹...")
    try:
        # æ­¥é©Ÿ 1: æå–éŸ³è¨Š
        audio_path_raw = os.path.join(temp_dir, "raw_audio.wav")
        st.write("   - æ­£åœ¨æå–éŸ³è¨Š...")
        (
            ffmpeg.input(video_path)
            .output(audio_path_raw, acodec='pcm_s16le', ar='16000', ac=1)
            .run(overwrite_output=True, quiet=True)
        )

        # æ­¥é©Ÿ 2: é›œè¨ŠæŠ‘åˆ¶
        st.write("   - æ­£åœ¨é€²è¡Œé›œè¨ŠæŠ‘åˆ¶...")
        rate, data = sf.read(audio_path_raw)

        # --- FIX START: å¢åŠ å°éŸ³è¨Šæ•¸æ“šçš„ç©©å¥æ€§æª¢æŸ¥ ---
        if not isinstance(data, np.ndarray) or data.size == 0:
            st.warning("   - åµæ¸¬åˆ°ç©ºéŸ³è¨Šæˆ–è®€å–å¤±æ•—ï¼Œè·³ééŸ³è¨Šè™•ç†ã€‚")
            st.success("ğŸ”Š éŸ³è¨Šæµç¨‹çµæŸï¼ˆç„¡å…§å®¹ï¼‰ã€‚")
            return None
        # --- FIX END ---

        if data.ndim > 1:
            data = np.mean(data, axis=1) # è½‰ç‚ºå–®è²é“
        
        # åƒ…åœ¨éŸ³è¨Šå¤ é•·æ™‚æ‰é€²è¡Œé™å™ª
        if len(data) > rate: # è‡³å°‘éœ€è¦1ç§’çš„éŸ³è¨Š
            reduced_noise_data = nr.reduce_noise(y=data, sr=rate)
        else:
            reduced_noise_data = data
        
        audio_path_processed = os.path.join(temp_dir, "processed_audio.wav")
        sf.write(audio_path_processed, reduced_noise_data, rate)

        # æ­¥é©Ÿ 3: èªéŸ³è¾¨è­˜ (Whisper)
        st.write("   - æ­£åœ¨é€²è¡ŒèªéŸ³è¾¨è­˜ (Whisper)...")
        model = whisper.load_model("tiny") 
        result = model.transcribe(audio_path_processed)
        transcript = result["text"]
        st.success("ğŸ”Š éŸ³è¨Šæµç¨‹å®Œæˆï¼")
        return transcript
    except Exception as e:
        st.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# 2. è¦–è¦ºè™•ç†
def process_visuals(video_path, temp_dir):
    """æå–é—œéµç•«é¢ä¸¦ç”¨ Gemini Vision ç†è§£"""
    st.info("ğŸ–¼ï¸ è¦–è¦ºæµç¨‹é–‹å§‹...")
    try:
        # æ­¥é©Ÿ 1: æ“·å–é—œéµç•«é¢
        st.write("   - æ­£åœ¨æ“·å–é—œéµç•«é¢...")
        key_frames_paths = []
        cap = cv2.VideoCapture(video_path)
        prev_frame = None
        frame_count = 0
        
        frame_extraction_placeholder = st.empty()

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ¯ç§’å–ä¸€å¹€é€²è¡Œæ¯”è¼ƒ
            fps = cap.get(cv2.CAP_PROP_FPS)
            if fps == 0: fps = 30 # é¿å…é™¤ä»¥é›¶
            
            if frame_count % int(fps) == 0:
                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                gray_frame = cv2.resize(gray_frame, (128, 72)) # ç¸®å°ä»¥åŠ é€Ÿ SSIM

                if prev_frame is not None:
                    similarity = ssim(prev_frame, gray_frame, data_range=gray_frame.max() - gray_frame.min())
                    if similarity < 0.9 or len(key_frames_paths) < 3: # ç›¸ä¼¼åº¦ä½æ–¼é–¾å€¼ï¼Œæˆ–æ“·å–æ•¸é‡å°‘æ–¼3å¼µæ™‚å¼·åˆ¶ä¿å­˜
                        frame_path = os.path.join(temp_dir, f"frame_{frame_count}.jpg")
                        cv2.imwrite(frame_path, frame)
                        key_frames_paths.append(frame_path)
                        frame_extraction_placeholder.write(f"      - å·²æ“·å– {len(key_frames_paths)} å€‹é—œéµç•«é¢...")
                else: # ä¿å­˜ç¬¬ä¸€å¹€
                    frame_path = os.path.join(temp_dir, f"frame_{frame_count}.jpg")
                    cv2.imwrite(frame_path, frame)
                    key_frames_paths.append(frame_path)
                
                prev_frame = gray_frame
            frame_count += 1
            if len(key_frames_paths) >= 8: # æœ€å¤šå–8å¼µé—œéµç•«é¢
                break
        
        cap.release()
        frame_extraction_placeholder.write(f"      - å…±æ“·å– {len(key_frames_paths)} å€‹é—œéµç•«é¢ã€‚")

        if not key_frames_paths:
            st.warning("   - æœªèƒ½æ“·å–ä»»ä½•é—œéµç•«é¢ã€‚")
            st.success("ğŸ–¼ï¸ è¦–è¦ºæµç¨‹çµæŸï¼ˆç„¡å…§å®¹ï¼‰ã€‚")
            return None

        # æ­¥é©Ÿ 2: åœ–åƒç†è§£
        st.write("   - æ­£åœ¨ç†è§£ç•«é¢å…§å®¹ (Gemini)...")
        descriptions = []
        image_analysis_placeholder = st.empty()

        # --- FIX START: æ›´æ–° Gemini Vision æ¨¡å‹ ---
        vision_model = genai.GenerativeModel('gemini-1.5-flash-latest')
        # --- FIX END ---
        
        for i, frame_path in enumerate(key_frames_paths):
            image_analysis_placeholder.write(f"      - æ­£åœ¨åˆ†æç¬¬ {i+1}/{len(key_frames_paths)} å¼µç•«é¢...")
            try:
                img = genai.upload_file(frame_path)
                response = vision_model.generate_content(["è«‹ç°¡è¦æè¿°é€™å¼µåœ–ç‰‡ä¸­çš„ä¸»è¦ç‰©é«”ã€å ´æ™¯å’Œæ°›åœã€‚", img])
                descriptions.append(response.text)
                time.sleep(1) # é¿å…è§¸ç™¼ API é »ç‡é™åˆ¶
            except Exception as e:
                st.warning(f"åˆ†æç•«é¢ {os.path.basename(frame_path)} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        st.success("ğŸ–¼ï¸ è¦–è¦ºæµç¨‹å®Œæˆï¼")
        return " ".join(descriptions)

    except Exception as e:
        st.error(f"è™•ç†è¦–è¦ºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# 3. LLM Hashtag ç”Ÿæˆ
def generate_hashtags(text_content, prompt_type):
    """ä½¿ç”¨ Gemini Pro å¾æ–‡æœ¬ç”Ÿæˆ Hashtag"""
    if not text_content or text_content.strip() == "":
        return []
    
    st.info(f"âœ¨ æ­£åœ¨å¾ {prompt_type} å…§å®¹ç”Ÿæˆ Hashtag...")
    try:
        # ä½¿ç”¨ gemini-1.5-flashï¼Œå› ç‚ºå®ƒé€Ÿåº¦å¿«ä¸”æ€§èƒ½å¥½
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ç¤¾ç¾¤åª’é«”è¡ŒéŠ·å°ˆå®¶ã€‚æ ¹æ“šä»¥ä¸‹å…§å®¹ï¼Œç”Ÿæˆ 8 å€‹æœ€ç›¸é—œã€æœ€å¸å¼•äººçš„ç¹é«”ä¸­æ–‡ Hashtagã€‚
        è«‹ç”¨ç©ºæ ¼åˆ†éš”æ¯å€‹ Hashtagï¼Œä¸è¦åŒ…å« '#' ç¬¦è™Ÿæˆ–å…¶ä»–å¤šé¤˜çš„æ–‡å­—ã€‚

        å…§å®¹ï¼š
        ---
        {text_content}
        ---

        Hashtags:
        """
        response = model.generate_content(prompt)
        # æ¸…ç†è¼¸å‡ºï¼Œç§»é™¤å¯èƒ½å‡ºç¾çš„markdownç­‰ç¬¦è™Ÿ
        cleaned_text = response.text.replace("*", "").replace("#", "").strip()
        hashtags = [tag.strip() for tag in cleaned_text.split()]
        st.success(f"âœ¨ {prompt_type} Hashtag å·²ç”Ÿæˆï¼")
        return hashtags
    except Exception as e:
        st.error(f"ç”Ÿæˆ Hashtag æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

# --- ä¸»åŸ·è¡Œæµç¨‹ ---
if st.button("ğŸš€ é–‹å§‹ç”Ÿæˆ Hashtag", disabled=(not uploaded_file or not api_key)):
    try:
        genai.configure(api_key=api_key)
        # å‰µå»ºä¸€å€‹è‡¨æ™‚ç›®éŒ„ä¾†å­˜æ”¾æ‰€æœ‰ä¸­é–“æª”æ¡ˆ
        with tempfile.TemporaryDirectory() as temp_dir:
            # ä¿å­˜ä¸Šå‚³çš„å½±ç‰‡
            video_path = os.path.join(temp_dir, uploaded_file.name)
            with open(video_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            with st.spinner("æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å€™...é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ã€‚"):
                # åŸ·è¡ŒéŸ³è¨Šå’Œè¦–è¦ºæµç¨‹
                transcript = process_audio(video_path, temp_dir)
                visual_descriptions = process_visuals(video_path, temp_dir)

                # ç”Ÿæˆ Hashtags
                audio_hashtags = []
                if transcript and transcript.strip():
                    st.subheader("ğŸ“ èªéŸ³è¾¨è­˜é€å­—ç¨¿")
                    st.text_area("Transcript", transcript, height=150)
                    audio_hashtags = generate_hashtags(transcript, "èªéŸ³")
                
                visual_hashtags = []
                if visual_descriptions and visual_descriptions.strip():
                    st.subheader("ğŸ¨ é—œéµç•«é¢æè¿°")
                    st.text_area("Visuals Description", visual_descriptions, height=150)
                    visual_hashtags = generate_hashtags(visual_descriptions, "è¦–è¦º")
                
                # åˆä½µèˆ‡å»é‡
                final_hashtags = sorted(list(set(audio_hashtags + visual_hashtags)))

                # é¡¯ç¤ºæœ€çµ‚çµæœ
                st.subheader("ğŸ‰ æœ€çµ‚ Hashtag æ¨è–¦")
                if final_hashtags:
                    # ä»¥æ¨™ç±¤å½¢å¼é¡¯ç¤º
                    tags_html = "".join([f"<span style='background-color: #1E90FF; color: white; padding: 5px 10px; border-radius: 15px; margin: 5px; display: inline-block;'>#{tag}</span>" for tag in final_hashtags])
                    st.markdown(tags_html, unsafe_allow_html=True)
                    
                    # æä¾›ä¸€å€‹å¯è¤‡è£½çš„ç´”æ–‡å­—ç‰ˆæœ¬
                    st.text_area("è¤‡è£½ Hashtags", " ".join([f"#{tag}" for tag in final_hashtags]))
                else:
                    st.warning("ç„¡æ³•ç”Ÿæˆä»»ä½• Hashtagã€‚å¯èƒ½æ˜¯å½±ç‰‡å…§å®¹ä¸è¶³æˆ–åœ¨è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ã€‚")

    except Exception as e:
        st.error(f"ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
        st.exception(e) # é¡¯ç¤ºè©³ç´°çš„éŒ¯èª¤è¿½è¹¤

# èªªæ˜
st.sidebar.markdown("---")
st.sidebar.markdown("### ä½¿ç”¨èªªæ˜")
st.sidebar.markdown("""
1.  åœ¨ä¸Šæ–¹è¼¸å…¥æ‚¨çš„ Google Gemini API Keyã€‚
2.  é»æ“Šä¸Šå‚³æŒ‰éˆ•ï¼Œé¸æ“‡ä¸€å€‹å½±ç‰‡æª”æ¡ˆã€‚
3.  é»æ“Šã€Œé–‹å§‹ç”Ÿæˆ Hashtagã€æŒ‰éˆ•ã€‚
4.  ç³»çµ±å°‡æœƒè™•ç†å½±ç‰‡ä¸¦åœ¨ä¸»ç•«é¢é¡¯ç¤ºçµæœã€‚
""")

st.sidebar.markdown("### å¿…è¦æ¢ä»¶")
st.sidebar.markdown("""
- **FFmpeg**: æ‚¨çš„ç³»çµ±å¿…é ˆå®‰è£ FFmpegã€‚è«‹åƒè€ƒ [FFmpeg å®˜ç¶²](https://ffmpeg.org/download.html) é€²è¡Œå®‰è£ã€‚
""")




